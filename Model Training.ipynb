{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ad666b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "iterTraverse the folders, one folder corresponds to one category\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import swin_tiny_patch4_window7_224 as create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d901d3",
   "metadata": {},
   "source": [
    "### 1. Divide the dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "544d696f",
   "metadata": {},
   "source": [
    "dataset--AD--\"001.nii.gz\"\n",
    "        --\"002.nii.gz\"\n",
    "        --\"003.nii.gz\" \n",
    "        --   ..... \n",
    "     \n",
    "     --CN--\"001.nii.gz\"\n",
    "        --\"002.nii.gz\"\n",
    "        --\"003.nii.gz\" \n",
    "        --   .....       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_split_data(root: str, val_rate: float = 0.1, test_rate: float = 0.1):\n",
    "    assert os.path.exists(root), \"dataset root: {} does not exist.\".format(root)\n",
    "\n",
    "    # Traverse the folders, one folder corresponds to one category\n",
    "    patient_class = [cla for cla in os.listdir(root) if os.path.isdir(os.path.join(root, cla))]\n",
    "\n",
    "    patient_class.sort()\n",
    "    # Generate category names and corresponding numeric indices\n",
    "    class_indices = dict((k, v) for v, k in enumerate(patient_class))\n",
    "    json_str = json.dumps(dict((val, key) for key, val in class_indices.items()), indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    #patient_class = ['AD','CN']\n",
    "    train_images_path = []  \n",
    "    train_images_label = []  \n",
    "    val_images_path = []  \n",
    "    val_images_label = []  \n",
    "    test_images_path = []  \n",
    "    test_images_label = [] \n",
    "    every_class_num = []  \n",
    "    supported = [\".gz\"]  \n",
    "    \n",
    "    # Traverse the files in each folder\n",
    "    for cla in patient_class:\n",
    "        cla_path = os.path.join(root, cla) # root/AD/\n",
    "    \n",
    "        images = [os.path.join(root, cla, i) for i in os.listdir(cla_path)\n",
    "                  if os.path.splitext(i)[-1] in supported]\n",
    "        \n",
    "        images.sort()\n",
    "        \n",
    "        image_class = class_indices[cla]\n",
    "        \n",
    "        every_class_num.append(len(images))\n",
    "        \n",
    "        val_test_path = random.sample(images, k=int(len(images) * 0.25))\n",
    "        #test_path = random.sample(val_test_path, k=int(len(val_test_path) * 0.5))\n",
    "        for img_path in images:\n",
    "            if img_path in val_test_path:  \n",
    "                val_images_path.append(img_path)\n",
    "                val_images_label.append(image_class)\n",
    "                \n",
    "#                 if img_path in test_path:  # 如果该路径在测试集样本中，则存入测试集\n",
    "#                     test_images_path.append(img_path)\n",
    "#                     test_images_label.append(image_class)\n",
    "#                 else:  # 否则存入验证集\n",
    "#                     val_images_path.append(img_path)\n",
    "#                     val_images_label.append(image_class)\n",
    "            else:  # 否则存入训练集\n",
    "                train_images_path.append(img_path)\n",
    "                train_images_label.append(image_class)\n",
    "\n",
    "    print(\"{} images were found in the dataset.\".format(sum(every_class_num)))\n",
    "    print(\"{} images for training.\".format(len(train_images_path)))\n",
    "    print(\"{} images for validation.\".format(len(val_images_path)))\n",
    "    print(\"{} images for test.\".format(len(test_images_path)))\n",
    "    assert len(train_images_path) > 0, \"number of training images must greater than 0.\"\n",
    "    assert len(val_images_path) > 0, \"number of validation images must greater than 0.\"\n",
    "    #assert len(test_images_path) > 0, \"number of test images must greater than 0.\"\n",
    "    plot_image = True\n",
    "    if plot_image:\n",
    "        \n",
    "        plt.bar(range(len(patient_class)), every_class_num, align='center')\n",
    "        \n",
    "        plt.xticks(range(len(patient_class)), patient_class)\n",
    "        \n",
    "        for i, v in enumerate(every_class_num):\n",
    "            plt.text(x=i, y=v + 5, s=str(v), ha='center')\n",
    "        \n",
    "        plt.xlabel('image class')\n",
    "        \n",
    "        plt.ylabel('number of images')\n",
    "        \n",
    "        plt.title('patient class distribution')\n",
    "        plt.show()\n",
    "\n",
    "    return train_images_path, train_images_label, val_images_path, val_images_label\n",
    "#, test_images_path, test_images_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec1d6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_images_path, train_images_label, val_images_path, val_images_label=read_split_data(\"/dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397c7ba",
   "metadata": {},
   "source": [
    "## 2. Define MONAI transforms and instantiate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, ImageDataset\n",
    "from monai import transforms\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([transforms.EnsureChannelFirst(),                            \n",
    "                                 transforms.CropForeground(k_divisible=1),\n",
    "                                 transforms.CenterSpatialCrop(roi_size=(112,121,64)), \n",
    "                                 transforms.RandSpatialCrop(roi_size=(80,90,44), max_roi_size=(-1,-1,-1), random_size=True), \n",
    "                                 transforms.Resize(spatial_size=(112,112,64)),  # resize\n",
    "                                 transforms.NormalizeIntensity(),\n",
    "                                 transforms.ScaleIntensity(),\n",
    "                                 \n",
    "                                 transforms.RandFlip(prob=0.5,spatial_axis=0),\n",
    "                                 transforms.RandFlip(prob=0.5,spatial_axis=1),\n",
    "                                 transforms.RandFlip(prob=0.5,spatial_axis=2),\n",
    "                                  transforms.RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "#                                  transforms.RandRotate90(prob=0.5, spatial_axes=(1, 2)),\n",
    "                                 transforms.ToTensor()  \n",
    "                                ]),\n",
    "    \"val\": transforms.Compose([transforms.EnsureChannelFirst(), \n",
    "                               \n",
    "                               transforms.CropForeground(k_divisible=1),\n",
    "                               transforms.CenterSpatialCrop(roi_size=(112,121,64)),\n",
    "                               #transforms.RandSpatialCrop(roi_size=(112,112,64), max_roi_size=(-1,-1,-1)), \n",
    "                               #transforms.CenterSpatialCrop(roi_size=(112,112,64)),\n",
    "                               transforms.Resize(spatial_size=(112,112,64)),\n",
    "                               transforms.NormalizeIntensity(),\n",
    "                               transforms.ScaleIntensity(),\n",
    "                               #transforms.Resize(spatial_size=(112,112,64)),  # resize\n",
    "                               transforms.ToTensor()  # 转为Tensor\n",
    "                              ]),\n",
    "    \"test\": transforms.Compose([transforms.EnsureChannelFirst(),  \n",
    "                                transforms.RepeatChannel(repeats=3),  \n",
    "                               transforms.CropForeground(k_divisible=1),\n",
    "                               transforms.Resize(spatial_size=(96,96,96)),  # resize\n",
    "                               transforms.ToTensor(),  # 转为Tensor\n",
    "                                #transforms.NormalizeIntensity()\n",
    "                               ])\n",
    "}\n",
    "\n",
    "# 实例化训练数据集\n",
    "train_dataset = ImageDataset(image_files=train_images_path,\n",
    "                          labels=train_images_label,\n",
    "                          transform=data_transform[\"train\"])\n",
    "\n",
    "# 实例化验证数据集\n",
    "val_dataset = ImageDataset(image_files=val_images_path,\n",
    "                        labels=val_images_label,\n",
    "                        transform=data_transform[\"val\"])\n",
    "\n",
    "# # 实例化测试数据集\n",
    "# test_dataset = ImageDataset(image_files=test_images_path,\n",
    "#                         labels=test_images_label,\n",
    "#                         transform=data_transform[\"test\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fcf33d",
   "metadata": {},
   "source": [
    "### 3. Loading dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1980f35f-3c2d-41bb-a56f-19d77ebf0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2   # can change\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True,\n",
    "                          num_workers=nw)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=nw)\n",
    "# test_loader = DataLoader(test_dataset,\n",
    "#                          batch_size=batch_size,\n",
    "#                          shuffle=False,\n",
    "#                          pin_memory=True,\n",
    "#                          num_workers=nw)\n",
    "train_num = len(train_dataset)\n",
    "val_num = len(val_dataset)\n",
    "# test_num = len(test_dataset)\n",
    "print(\"using {} images for training, {} images for validation\".format(train_num, \n",
    "                                                                                          val_num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657ca19",
   "metadata": {},
   "source": [
    "### 4. Display a slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# image (B, C，D, H, W)\n",
    "#       (1, 1, 64, 112, 112)\n",
    "for k,data in enumerate(train_loader):\n",
    "    data[0] = data[0].permute(0,1, 4, 3, 2)\n",
    "    \n",
    "    print(data[0].shape)\n",
    "    image = data[0]\n",
    "    label = data[1]\n",
    "    data_img=np.array(image)\n",
    "    label_img=np.array(label)\n",
    "    print(data_img.shape)\n",
    "    print(label_img[0])\n",
    "    \n",
    "    x_slice_data = data_img[0,0,30, :,:]\n",
    "    plt.imshow(x_slice_data,cmap='gray')\n",
    "    #plt.title(class_indict['0'])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0d991f",
   "metadata": {},
   "source": [
    "### 5. Load the pre-training weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef06989",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The pre-training parameters of the original Video Swin Transformer are available for download on github. \n",
    "## You can also not initialize the weights.\n",
    "weights = './swin_tiny_patch244_window877_kinetics400_1k.pth'\n",
    "predict_model = torch.load(weights)\n",
    "#print(predict_model['state_dict'].keys())\n",
    "\n",
    "\n",
    "predict_model['state_dict'] = {key.replace('backbone.', ''): value for key, value in predict_model['state_dict'].items()}\n",
    "#print(predict_model['state_dict'].keys())\n",
    "\n",
    "\n",
    "## Match the weight of the video swin Transformer. Do not use other weights.\n",
    "for k in list(predict_model['state_dict'].keys()):\n",
    "    if \"patch_embed\" in k:\n",
    "        del predict_model['state_dict'][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d470b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model(num_classes=2, init_weights=True).to(device)\n",
    "net_dict = model.state_dict()\n",
    "#print(net_dict.keys())\n",
    "#print(predict_model['state_dict'].items())\n",
    "\n",
    "state_dict = {k: v for k, v in predict_model['state_dict'].items() if k in net_dict.keys()}\n",
    "\n",
    "print(state_dict.keys())\n",
    "net_dict.update(state_dict)  \n",
    "model.load_state_dict(net_dict) \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a60dd",
   "metadata": {},
   "source": [
    "### 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa6394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "#pg = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.000005, weight_decay=1e-1) # 下一次用5e-3试试  verbose=true\n",
    "#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=400, eta_min=0, last_epoch=-1)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2, eta_min=1e-7, last_epoch=-1, verbose=False)#2E-7\n",
    "epochs = 550\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "train_loss=[]\n",
    "val_loss = []\n",
    "tra_acc = []\n",
    "val_acc=[]\n",
    "\n",
    "# Save the weights after training\n",
    "save_path = './files/xxxxxxxxxx.pth'\n",
    "train_steps = len(train_loader)\n",
    "val_steps = len(val_loader)\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    train_acc = 0\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)  # 返回一个迭代器\n",
    "    for step, data in enumerate(train_bar):\n",
    "        images, labels = data\n",
    "        # 修改输入\n",
    "        images = images.permute(0,1, 4, 3, 2)\n",
    "        #print(images.shape)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(images.to(device))\n",
    "        loss = loss_function(pred, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred_train = torch.argmax(pred, dim=1)\n",
    "        train_acc += torch.eq(pred_train, labels.to(device)).sum().item()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Progress bar description\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, running_loss/(step+1))\n",
    "    scheduler.step()\n",
    "    print(optimizer.state_dict()['param_groups'][0]['lr'])  # print lr\n",
    "    train_loss.append(running_loss / len(train_loader))\n",
    "\n",
    "    # validate\n",
    "    #optimizer.zero_grad()\n",
    "    model.eval()\n",
    "    acc_loss = 0.0\n",
    "    acc = 0.0  # accumulate accurate number / epoch\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, file=sys.stdout)\n",
    "        for val_step, val_data in enumerate(val_bar):\n",
    "            val_images, val_labels = val_data\n",
    "            # 修改输入\n",
    "            val_images = val_images.permute(0,1, 4, 3, 2)\n",
    "            pred = model(val_images.to(device))\n",
    "            # Calculation and verification loss\n",
    "        \n",
    "            loss = loss_function(pred, val_labels.to(device))\n",
    "            acc_loss += loss.item()\n",
    "            predict_y = torch.argmax(pred, dim=1)\n",
    "            #print( pred)\n",
    "            #print( predict_y)\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "           # print( val_labels.to(device))\n",
    "    train_accurate = train_acc / train_num\n",
    "    val_accurate = acc / val_num\n",
    "    tra_acc.append(train_accurate)\n",
    "    val_acc.append(val_accurate)\n",
    "    val_loss.append(acc_loss / len(val_loader))\n",
    "    print('[epoch %d] train_loss: %.3f  train_accuracy:%.3f  val_loss:%.3f  val_accuracy: %.3f' %\n",
    "          (epoch + 1, running_loss / train_steps,train_accurate, acc_loss / val_steps, val_accurate))\n",
    "\n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "epochs = range(len(train_loss))\n",
    "plt.plot(epochs, train_loss, 'g', label='Loss of Training data')\n",
    "plt.plot(epochs, val_loss, 'b', label='Loss of Val data')\n",
    "plt.plot(epochs, val_acc, 'r', label='Acc of Val data')\n",
    "plt.plot(epochs, tra_acc, label='Acc of Train data')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(best_acc)\n",
    "print(best_epoch)\n",
    "np.save('./files/train_loss1.npy', train_loss)\n",
    "np.save('./files/val_loss1.npy', val_loss)\n",
    "np.save('./files/val_acc1.npy', val_acc)\n",
    "np.save('./files/tra_acc1.npy', tra_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b06d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_ls = np.load('./files/train_loss1.npy')\n",
    "val_ls = np.load('./files/val_loss1.npy')\n",
    "tra_ac = np.load('./files/tra_acc1.npy')\n",
    "val_ls = np.load('./files/val_acc1.npy')\n",
    "epochs = range(len(train_loss))\n",
    "plt.plot(epochs, train_loss, 'g', label='Loss of Training data')\n",
    "plt.plot(epochs, val_loss, 'b', label='Loss of Val data')\n",
    "plt.plot(epochs, val_acc, 'r', label='Acc of Val data')\n",
    "plt.plot(epochs, tra_acc, label='Acc of Train data')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read class_indict\n",
    "json_path = './class_indices.json'\n",
    "assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    class_indict = json.load(f)\n",
    "\n",
    "print(class_indict)\n",
    "class_indict = {'0':'AD',\n",
    "                 '1':'CN'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c0753",
   "metadata": {},
   "source": [
    "### 7. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# load model weights\n",
    "weights_path = './files/xxxxxxx.pth'\n",
    "assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "\n",
    "predictions = []  \n",
    "labels = []  \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(val_loader, file=sys.stdout)\n",
    "    for test_data in test_bar:\n",
    "        test_images, test_labels = test_data\n",
    "        test_images = test_images.permute(0,1, 4, 3, 2)\n",
    "        outputs = model(test_images.to(device))\n",
    "        predict_y = torch.max(outputs, dim=1)[1].cpu()  \n",
    "        predictions.extend(predict_y.numpy())\n",
    "        labels.extend(test_labels.cpu().numpy())\n",
    "        \n",
    "predictions = np.array(predictions)\n",
    "labels = np.array(labels)\n",
    "# Print evaluation report\n",
    "print(classification_report(labels, predictions, target_names=class_indict.values()))\n",
    "\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39becc",
   "metadata": {},
   "source": [
    "### 8.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels, predictions)\n",
    "cm_df = pd.DataFrame(cm, index=class_indict.values(), columns=class_indict.values())\n",
    "cm_df\n",
    "plt.figure( dpi=300)\n",
    "sns.heatmap(cm_df, annot=True, cmap=\"Blues\", fmt=\".1f\")\n",
    "plt.title(\"Confusion Matrix\", fontweight=\"bold\")\n",
    "plt.xlabel(\"Predicted\", fontweight=\"bold\")\n",
    "plt.ylabel(\"True\", fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f2adb",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "无",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
